<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.0.1">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.0.1">


  <link rel="mask-icon" href="/images/logo.svg?v=7.0.1" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.0.1',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="1 概述利用一组带有标签的数据，学习从输入到输出映射，然后将这种关系应用到未知数据上，达分类或回归的目的。分类：当输出是离散的，学习任务为分类任务。回归：当输出是连续的，学习任务为回归任务。 1.1 分类学习输入：一组有标签的训练数据(也称观察和评估)，标签表明了这些数据（观察）的所署类别。输出：分类模型根据这些训练数据，训练自己的模型参数，学习出一个适合这组数据的分类器，当有新数据（非训练数据）">
<meta name="keywords" content="机器学习,python">
<meta property="og:type" content="article">
<meta property="og:title" content="监督学习">
<meta property="og:url" content="http://yoursite.com/post/6886.html">
<meta property="og:site_name" content="Booboo">
<meta property="og:description" content="1 概述利用一组带有标签的数据，学习从输入到输出映射，然后将这种关系应用到未知数据上，达分类或回归的目的。分类：当输出是离散的，学习任务为分类任务。回归：当输出是连续的，学习任务为回归任务。 1.1 分类学习输入：一组有标签的训练数据(也称观察和评估)，标签表明了这些数据（观察）的所署类别。输出：分类模型根据这些训练数据，训练自己的模型参数，学习出一个适合这组数据的分类器，当有新数据（非训练数据）">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://polq2xceb.bkt.clouddn.com/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/%E5%8D%81%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E7%A4%BA%E6%84%8F%E5%9B%BE.png">
<meta property="og:image" content="http://polq2xceb.bkt.clouddn.com/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/KNN%E7%AE%97%E6%B3%95%E7%A4%BA%E4%BE%8B.png">
<meta property="og:image" content="http://polq2xceb.bkt.clouddn.com/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/%E4%BF%A1%E7%94%A8%E5%8D%A1%E5%81%BF%E8%BF%98%E8%83%BD%E5%8A%9B%E5%88%86%E7%B1%BB%E5%86%B3%E7%AD%96%E6%A0%91.png">
<meta property="og:image" content="http://polq2xceb.bkt.clouddn.com/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/output_16_0.png">
<meta property="og:image" content="http://polq2xceb.bkt.clouddn.com/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/output_18_0.png">
<meta property="og:image" content="http://polq2xceb.bkt.clouddn.com/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/output_20_1.png">
<meta property="og:updated_time" content="2019-03-22T12:00:20.876Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="监督学习">
<meta name="twitter:description" content="1 概述利用一组带有标签的数据，学习从输入到输出映射，然后将这种关系应用到未知数据上，达分类或回归的目的。分类：当输出是离散的，学习任务为分类任务。回归：当输出是连续的，学习任务为回归任务。 1.1 分类学习输入：一组有标签的训练数据(也称观察和评估)，标签表明了这些数据（观察）的所署类别。输出：分类模型根据这些训练数据，训练自己的模型参数，学习出一个适合这组数据的分类器，当有新数据（非训练数据）">
<meta name="twitter:image" content="http://polq2xceb.bkt.clouddn.com/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/%E5%8D%81%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E7%A4%BA%E6%84%8F%E5%9B%BE.png">






  <link rel="canonical" href="http://yoursite.com/post/6886.html">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>监督学习 | Booboo</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Booboo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Navigationsleiste an/ausschalten">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Startseite</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Schlagwörter</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Kategorien</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archiv</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-resume">

    
    
    
      
    

    

    <a href="/resume/" rel="section"><i class="menu-item-icon fa fa-fw fa-user-o"></i> <br>resume</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    
  
  
  
  

  

  <a href="https://github.com/wavezhu" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewbox="0 0 250 250" style="fill: #222; color: #fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a>



    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/post/6886.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="WaveZhu">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Booboo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">监督学习

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-03-22 17:53:21 / Geändert am: 20:00:20" itemprop="dateCreated datePublished" datetime="2019-03-22T17:53:21+08:00">2019-03-22</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1 概述"></a>1 概述</h2><p>利用一组<strong>带有标签</strong>的数据，学习从输入到输出映射，然后将这种关系应用到未知数据上，达分类或回归的目的。<br>分类：当输出是离散的，学习任务为分类任务。<br>回归：当输出是连续的，学习任务为回归任务。</p>
<h3 id="1-1-分类学习"><a href="#1-1-分类学习" class="headerlink" title="1.1 分类学习"></a>1.1 分类学习</h3><p>输入：一组有标签的训练数据(也称观察和评估)，标签表明了这些数据（观察）的所署类别。<br>输出：分类模型根据这些训练数据，训练自己的模型参数，学习出一个适合这组数据的分类器，当有新数据（非训练数据）需要进行类别判断，就可以将这组新数据作为输入送给学好的分类器进行判断。<br><a id="more"></a><br>在sklearn机器学习库中，与聚类算法被统一封装在sklearn.cluster模块不同，sklearn库中的分类算法并未被统一封装在一个子模块中，因此对分类算法的import方式各有不同。</p>
<h3 id="1-2-分类学习评价"><a href="#1-2-分类学习评价" class="headerlink" title="1.2 分类学习评价"></a>1.2 分类学习评价</h3><ul>
<li>训练集(training set):顾名思义用来训练模型的已标注数据，用来建立模型，发现规律。</li>
<li>测试集(testing set):也是已标注数据，通常做法是将标注隐藏，输送给训练好的模型，通过结果与真实标注进行对比，评估模型的学习能力。  </li>
</ul>
<p>训练集/测试集的划分方法:根据已有标注数据，随机选出一部分数据(70%)数据作为训练数据，余下的作为测试数据，此外还有交叉验证法自助法用来评估分类模型。</p>
<p>精确率:精确率是针对我们预测结果而言的，(以二分类为例)它表示的是预测为正的样本中有多少是真正的正样本。那么预测为正就有两种可能了，一种就是把正类预测为正类(TP)，另一种就是把负类预测为正类(FP)，也就是$$P=\frac{TP}{TP+FP}$$<br>召回率:是针对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确了。那也有两种可能，一种是把原来的正类预测成正类(TP)，另一种就是把原来的正类预测为负类(FN)，也就是$$R=\frac{TP}{TP+FN}$$   </p>
<h3 id="1-3-回归学习"><a href="#1-3-回归学习" class="headerlink" title="1.3 回归学习"></a>1.3 回归学习</h3><p>统计学分析数据的方法，目的在于了解两个或多个变数间是否相关、研究其相关方向与强度，并建立数学模型以便观察特定变数来预测研究者感兴趣的变数。回归分析可以帮助人们了解在自变量变化时因变量的变化量。一般来说，通过回归分析我们可以由给出的自变量估计因变量的条件期望。  </p>
<p>sklearn机器学习库提供的回归函数主要被封装在两个子模块中，分别是sklearn.linear_model和sklearn.preprocessing。<br>sklearn.linear_modlel封装的是一些线性函数，线性回归函数包括有:普通线性回归函数(LinearRegression)、岭回归(Ridge)、Lasso(Lasso)。<br>非线性回归函数，如多项式回归(PolynomialFeatures)则通过sklearn .preprocessing子模块进行调用。    </p>
<h3 id="1-4-交叉验证"><a href="#1-4-交叉验证" class="headerlink" title="1.4 交叉验证"></a>1.4 交叉验证</h3><p>交叉验证法先将数据集D划分为k个大小相似的互斥子集，每个自己都尽可能保持数据分布的一致性，即从D中通过分层采样得到。然后，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集；这样就可获得k组训练/测试集，从而可进行k次训练和测试，最终返回的是这个k个测试结果的均值。通常把交叉验证法称为“k者交叉验证”, k最常用的取值是10，此时称为10折交叉验证。</p>
<div align="center"><img src="http://polq2xceb.bkt.clouddn.com/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/%E5%8D%81%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E7%A4%BA%E6%84%8F%E5%9B%BE.png" style="width:400px;height:300px;"></div>

<h2 id="2-K临近分类器"><a href="#2-K临近分类器" class="headerlink" title="2 K临近分类器"></a>2 K临近分类器</h2><h3 id="2-1-算法思想"><a href="#2-1-算法思想" class="headerlink" title="2.1 算法思想"></a>2.1 算法思想</h3><p>K临近分类器（KNN，k-nearest neighbors algorithm）通过计算待分类数据点，与已有数据集中的所有数据点的距离。取距离最小的前K个点，根据“少数服从多数“的原则，将这个数据点划分为出现次数最多的那个类别。  </p>
<p><div align="center"><img src="http://polq2xceb.bkt.clouddn.com/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/KNN%E7%AE%97%E6%B3%95%E7%A4%BA%E4%BE%8B.png" style="width:400px;height:300px;"></div><br>如图所示。测试样本（绿色圆形）应归入要么是第一类的蓝色方形或是第二类的红色三角形。如果k=3（实线圆圈）它被分配给第二类，因为有2个三角形和只有1个正方形在内侧圆圈之内。如果k=5（虚线圆圈）它被分配到第一类（3个正方形与2个三角形在外侧圆圈之内）。  </p>
<h3 id="2-2-sklearn库实现步骤"><a href="#2-2-sklearn库实现步骤" class="headerlink" title="2.2 sklearn库实现步骤"></a>2.2 sklearn库实现步骤</h3><p>在sklearn库中，可以使用sklearn.neighbors.KNeighborsClassifier创建一个K近邻分类器，主要参数有:</p>
<ul>
<li>n-neighbors用于指定分类器中K的大小(默认值为5，注意与kmeans的区别)</li>
<li>weights:设置选中的K个点对分类结果影响的权重(默认值为平均权重“uniform”，可以选择“distance“代表越近的点权重越高，或者传入自己编写的以距离为参数的权重计算函数)</li>
<li>algorithm:设置用于计算临近点的方法，因为当数据量很大的情况下计算当前点和所有点的距离再选出最近的k各点，这个计算量是很费时的，所以(选项中有ball_tree, kd_tree和brute，分别代表不同的寻找邻居的优化算法，默认值为auto，根据训练数据自动选择)  </li>
</ul>
<h3 id="2-3-算法应用"><a href="#2-3-算法应用" class="headerlink" title="2.3 算法应用"></a>2.3 算法应用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一组数据X和它对应的标签y</span></span><br><span class="line">X = [[<span class="number">0</span>],[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>]]</span><br><span class="line">y = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>]</span><br><span class="line"><span class="comment">#参数n_neifhbors设置为3，即使用最近的3个邻居作为分类的依据，其他参数保持默认值，并将创建好的示例赋给变量neigh</span></span><br><span class="line">neigh = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line"><span class="comment">#调用fit()函数，将训练数据X和biaoqiany送入分类器进行学习。</span></span><br><span class="line">neigh.fit(X,y)</span><br><span class="line"><span class="comment">#调用predict()函数，对位置分类样本[1.1]进行分类，可以直接并将需要分类的数据构造为数组形式作为参数传入，得到分类标签作为返回值。</span></span><br><span class="line">print(neigh.predict([[<span class="number">1.1</span>]]))</span><br><span class="line"><span class="comment">#样例输出值是0，表示K临近分类器通过计算样本[1.1]与训练数据的距离，取0，1，2这3个邻居作为依据，根据“投票法”最终将样本分为类别0。</span></span><br></pre></td></tr></table></figure>
<pre><code>[0]
</code></pre><p>在实际使用时，我们可以使用所有训练数据构成特征X和标签y，使用fit()函数进行训练。在正式分类时，通过一次性构造测试集或者一个一个输入样本的方式，得到样本对应的分类结果。有关K的取值:</p>
<ul>
<li>如果较大，相当于使用较大邻域中的训练实例进行预测，可以减小估计误差，但是距离较远的样本也会对预测起作用，导致预测错误。</li>
<li>相反地，如果K较小，相当于使用较小的邻域进行预测，如果邻居恰好是噪声点，会导致过拟合。</li>
<li>一般情况下，K会倾向选取较小的值，并使用交叉验证法选取最优K值。</li>
</ul>
<h2 id="3-决策树分类器"><a href="#3-决策树分类器" class="headerlink" title="3 决策树分类器"></a>3 决策树分类器</h2><h3 id="3-1-算法思想"><a href="#3-1-算法思想" class="headerlink" title="3.1 算法思想"></a>3.1 算法思想</h3><p>决策树是一种树形结构的分类器，通过顺序询问分类点的属性决定分类点最终的类别。通常根据特征的信息增益或其他指标，构建一颗决策树。在分类时，只需要按照决策树中的结点依次进行判断，即可得到样本所属类别。</p>
<p><div align="center"><img src="http://polq2xceb.bkt.clouddn.com/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/%E4%BF%A1%E7%94%A8%E5%8D%A1%E5%81%BF%E8%BF%98%E8%83%BD%E5%8A%9B%E5%88%86%E7%B1%BB%E5%86%B3%E7%AD%96%E6%A0%91.png" style="width:300px;height:200px;"></div><br>例如，根据上图这个构造好的分类决策树，一个无房产，单身，年收入55K的人的会被归入无法偿还信用卡这个类别。   </p>
<h3 id="3-2-sklearn库实现步骤"><a href="#3-2-sklearn库实现步骤" class="headerlink" title="3.2 sklearn库实现步骤"></a>3.2 sklearn库实现步骤</h3><p>在sklearn库中，可以使用sklearn.tree.DecisionTreeClassifier创建一个决策树用于分类，其主要参数有:  </p>
<ul>
<li>criterion:用于选择属性的准则，可以传入“gini“代表基尼系数，或者“entropy“代表信息增益。</li>
<li>max features:表示在决策树结点进行分裂时，从多少个特征中选择最优特征。可以设定固定数目、百分比或其他标准。它的默认值是使用所有特征个数。</li>
</ul>
<h3 id="3-3-算法应用"><a href="#3-3-算法应用" class="headerlink" title="3.3 算法应用"></a>3.3 算法应用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用默认参数，创建一颗基于基尼系数的决策树，并将该决策树分类器赋值给变量clf</span></span><br><span class="line">clf = DecisionTreeClassifier()</span><br><span class="line"><span class="comment">#将鸢尾花数据赋值给变量iris</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"><span class="comment">#将决策树分类器做为待评估的模型，iris.data鸢尾花数据作为特征，</span></span><br><span class="line"><span class="comment">#iris.target鸢尾花分类标签做为目标结果，通过设定cv为10，使用10折交叉验证。得到最终的交叉验证得分</span></span><br><span class="line">score = cross_val_score(clf,iris.data,iris.target, cv=<span class="number">10</span>)</span><br><span class="line">print(score)</span><br></pre></td></tr></table></figure>
<pre><code>[ 1.          0.93333333  1.          0.93333333  0.93333333  0.86666667
  0.93333333  1.          1.          1.        ]
</code></pre><p>决策树本质上是寻找一种对特征空间上的划分，旨在构建一个训练数据拟合的好，并且复杂度小的决策树。<br>在实际使用中，需要根据数据情况，调整DecisionTreeClassifier类中传入的参数，比如选择合适的criterion，设置随机变量等。    </p>
<h2 id="4-朴素贝叶斯分类器"><a href="#4-朴素贝叶斯分类器" class="headerlink" title="4 朴素贝叶斯分类器"></a>4 朴素贝叶斯分类器</h2><h3 id="4-1-算法思想"><a href="#4-1-算法思想" class="headerlink" title="4.1 算法思想"></a>4.1 算法思想</h3><p>朴素贝叶斯分类器是一个以贝叶斯定理为基础的多分类的分类器。对于给定数据，首先基于特征的条件独立性假设，学习输入输出的联合概率分布，然后基于此模型，对给定的输入X，利用贝叶斯定理求出后验概率最大的输出y。<br>$$p(A|B)=\frac{p(B|A)\cdot p(A)}{p(B)}$$  </p>
<h3 id="4-2-sklearn库实现步骤"><a href="#4-2-sklearn库实现步骤" class="headerlink" title="4.2 sklearn库实现步骤"></a>4.2 sklearn库实现步骤</h3><p>在sklearn库中，实现了三个朴素贝叶斯分类器，如下表所示</p>
<table>
<thead>
<tr>
<th>分类器</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>naive-bayes.G ussianNB</td>
<td>高斯朴素贝叶斯</td>
</tr>
<tr>
<td>naive-bayes.MultinomiaINB</td>
<td>针对多项式模型的朴素贝叶斯分类器</td>
</tr>
<tr>
<td>naive-bayes.BernouIliNB</td>
<td>针对多元伯努利模型的朴素贝叶斯分类器</td>
</tr>
</tbody>
</table>
<p>区别在于假设某一特征的所有属于某个类别的观测值符合特定分布，如分类问题的特征包括人的身高，身高符合高斯分布，这类问题适合高斯朴素贝叶斯。</p>
<p>在sklearn库中，可以使用sklearn.naive-bayes.GaussianNB创建一个高斯朴素贝叶斯分类器，其参数有:</p>
<ul>
<li>priors:给定各个类别的先验概率。如果为空，则按训练数据的实际情况进行统计;如果给定先验概率，则在训练过程中不能更改。  </li>
</ul>
<h3 id="4-3-算法应用"><a href="#4-3-算法应用" class="headerlink" title="4.3 算法应用"></a>4.3 算法应用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"><span class="comment"># 构造训练数据X和Y</span></span><br><span class="line">X = np.array([[<span class="number">-1</span>,<span class="number">-1</span>],[<span class="number">-2</span>,<span class="number">-1</span>],[<span class="number">-3</span>,<span class="number">-2</span>],[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">2</span>]])</span><br><span class="line">Y = np.array([<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line"><span class="comment">#使用默认参数，创建一个高斯朴素贝叶斯分类器，并将该分类器赋给变量clf</span></span><br><span class="line">clf = GaussianNB(priors=<span class="literal">None</span>)</span><br><span class="line"><span class="comment">#使用fit()函数进行训练，并使用predict()函数进行预测，得到预测结果为1</span></span><br><span class="line">clf.fit(X,Y)</span><br><span class="line">print(clf.predict([[<span class="number">-0.8</span>,<span class="number">-1</span>]]))</span><br></pre></td></tr></table></figure>
<pre><code>[1]
</code></pre><p>朴素贝叶斯是典型的生成学习方法，由训练数据学习联合概率分布，并求得后验概率分布。<br>朴素贝叶斯一般在小规模数据上的表现很好，适合进行多分类任务。</p>
<h2 id="5-人体运动状态预测"><a href="#5-人体运动状态预测" class="headerlink" title="5 人体运动状态预测"></a>5 人体运动状态预测</h2><h3 id="5-1-数据介绍"><a href="#5-1-数据介绍" class="headerlink" title="5.1 数据介绍"></a>5.1 数据介绍</h3><p>现已收集了来自A, B, C, D, E 5位用户的可穿戴设备上的传感器数据，每位用户的数据集包含一个特征文件(a.feature)和一个标签文件(a .label)。<br>特征文件中每一行对应一个时刻的所有传感器数值，标签文件中每行记录了和特征文件中对应时刻的标记过的用户姿态，两个文件的行数相同，相同行之间互相对应。</p>
<p>特征文件的各项特征具体如下表所示：</p>
<table>
<thead>
<tr>
<th>1</th>
<th>2</th>
<th>3-15</th>
<th>16-28</th>
<th>29-41</th>
</tr>
</thead>
<tbody>
<tr>
<td>时间戳</td>
<td>心率</td>
<td>传感器1</td>
<td>传感器2</td>
<td>传感器3</td>
</tr>
</tbody>
</table>
<p>在传感器1对应的13列数据特征中，包含:1项温度数据、3项一型三轴加速度数据、3项二型三轴加速度数据、3项三轴陀螺仪数据和3项三轴磁场数据。</p>
<table>
<thead>
<tr>
<th>3</th>
<th>4-6</th>
<th>7-9</th>
<th>10-12</th>
<th>13-15</th>
</tr>
</thead>
<tbody>
<tr>
<td>温度</td>
<td>一型三轴加速度</td>
<td>二型三轴加速度</td>
<td>三轴陀螺仪</td>
<td>三轴磁场</td>
</tr>
</tbody>
</table>
<ol>
<li>人体的温度数据可以反映当前活动的剧烈程度，一般在静止状态时，体温趋于稳定在36.5度上下;当温度高于37度时，可能是进行短时间的剧烈运动，比如跑步和骑行。  </li>
<li>在数据中有两个型号的加速度传感器，可以通过互相印证的方式，保证数据的完整性和准确性。通过加速度传感器对应的三个数值，可以知道空间中x,y,z三个轴上对应的加速度，而空间上的加速度和用户的姿态有密切的关系，比如用户向上起跳时，Z轴上的加速度会激增。</li>
<li>陀螺仪是角运动检测的常用仪器，可以判断出用户佩戴传感器时的身体角度是水平、倾斜还是垂直。直观地，通过这些数值都是推断姿态的重要指标。</li>
<li>磁场传感器可以检测用户周围的磁场强度和数值大小，这些数据可以帮助我们理解用户所处的环境。比如在一个办公场所，用户座位附近的磁场是大体上固定的，当磁场发生改变时，我们可以推断用户的位置和场景发生了变化。</li>
</ol>
<p>标签文件的每一行代表与特征文件中对应行的用户姿态类别。总共有0-24共25种身体姿态，如，无活动状态，坐态、跑态等。标签文件作为训练集的标准参考准则，可以进行特征的监督学习。   </p>
<h3 id="5-2-实验目的"><a href="#5-2-实验目的" class="headerlink" title="5.2 实验目的"></a>5.2 实验目的</h3><p>根据已有传感器的数据，判断新用户的姿态。或同一用户的传感器采集了新的数据，根据新的数据判断当前用户的姿态呢。</p>
<h3 id="5-3-具体实现"><a href="#5-3-具体实现" class="headerlink" title="5.3 具体实现"></a>5.3 具体实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据导入函数，设置传入两个参数，分别是特征文件的列表feature_paths和标签文件的列表labels_paths</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_datasets</span><span class="params">(feature_paths, label_paths)</span>:</span></span><br><span class="line">    <span class="comment">#定义feature数组变量，列数量和特征维度一致为41；定义labels标签变量，列数量与标签维度一致为1</span></span><br><span class="line">    feature = np.ndarray(shape=(<span class="number">0</span>,<span class="number">41</span>))</span><br><span class="line">    label = np.ndarray(shape=(<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> feature_paths:</span><br><span class="line">        <span class="comment">#使用panda库中的read_table函数读取一个特征文件的内容，其中指定分隔符为逗号，缺失值为问号且文件不包含表头行</span></span><br><span class="line">        df = pd.read_table(file, delimiter=<span class="string">','</span>, na_values=<span class="string">'?'</span>, header=<span class="literal">None</span>)</span><br><span class="line">        <span class="comment">#使用Imputer函数，通过设定strategy参数为‘mean’，使用平均值对缺失数据进行补全</span></span><br><span class="line">        imp = Imputer(missing_values=<span class="string">'NaN'</span>, strategy=<span class="string">'mean'</span>, axis=<span class="number">0</span>)</span><br><span class="line">        <span class="comment">#fit()函数用于训练预处理器，transform()函数用于生成预处理结果</span></span><br><span class="line">        imp.fit(df)</span><br><span class="line">        df = imp.transform(df)</span><br><span class="line">        <span class="comment">#将预处理后的数据加入feature，依次遍历完所有特征文件</span></span><br><span class="line">        feature = np.concatenate((feature, df))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> label_paths:</span><br><span class="line">        <span class="comment">#读取标签数据，文件不包含表头</span></span><br><span class="line">        df = pd.read_table(file, header=<span class="literal">None</span>)</span><br><span class="line">        <span class="comment">#将新读入的数据合并到标签集合中</span></span><br><span class="line">        label = np.concatenate((label, df))</span><br><span class="line">    <span class="comment">#将标签归整为一维向量</span></span><br><span class="line">    label = np.ravel(label)</span><br><span class="line">    <span class="keyword">return</span> feature, label</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment">#设置数据路径</span></span><br><span class="line">    featurePaths = [<span class="string">'datasets/A/A.feature'</span>,<span class="string">'datasets/B/B.feature'</span>,<span class="string">'datasets/C/C.feature'</span>,<span class="string">'datasets/D/D.feature'</span>,<span class="string">'datasets/E/E.feature'</span>]</span><br><span class="line">    labelPaths = [<span class="string">'datasets/A/A.label'</span>,<span class="string">'datasets/B/B.label'</span>,<span class="string">'datasets/C/C.label'</span>,<span class="string">'datasets/D/D.label'</span>,<span class="string">'datasets/E/E.label'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#将前四个数据作为训练集读入</span></span><br><span class="line">    x_train,y_train = load_datasets(featurePaths[:<span class="number">4</span>],labelPaths[:<span class="number">4</span>])</span><br><span class="line">    <span class="comment">#将最后一个数据作为测试集读入</span></span><br><span class="line">    x_test,y_test = load_datasets(featurePaths[<span class="number">4</span>:],labelPaths[<span class="number">4</span>:])</span><br><span class="line">    <span class="comment">#使用全量数据作为训练集，借助train_test_split函数将训练数据打乱</span></span><br><span class="line">    x_train, x_, y_train, y_ = train_test_split(x_train, y_train, test_size = <span class="number">0.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#创建k邻近分类器，并在测试集上进行预测</span></span><br><span class="line">    print(<span class="string">'Start training knn'</span>)</span><br><span class="line">    knn = KNeighborsClassifier().fit(x_train, y_train)</span><br><span class="line">    print(<span class="string">'Training done'</span>)</span><br><span class="line">    answer_knn = knn.predict(x_test)</span><br><span class="line">    print(<span class="string">'Prediction done'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#创建决策树分类器，并在测试集上进行预测</span></span><br><span class="line">    print(<span class="string">'Start training DT'</span>)</span><br><span class="line">    dt = DecisionTreeClassifier().fit(x_train, y_train)</span><br><span class="line">    print(<span class="string">'Training done'</span>)</span><br><span class="line">    answer_dt = dt.predict(x_test)</span><br><span class="line">    print(<span class="string">'Prediction done'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#创建贝叶斯分类器，并在测试集上进行预测</span></span><br><span class="line">    print(<span class="string">'Start training Bayes'</span>)</span><br><span class="line">    gnb = GaussianNB().fit(x_train, y_train)</span><br><span class="line">    print(<span class="string">'Training done'</span>)</span><br><span class="line">    answer_gnb = gnb.predict(x_test)</span><br><span class="line">    print(<span class="string">'Prediction done'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算准确率、召回率、f1值和支持度</span></span><br><span class="line">    print(<span class="string">'\n\nThe classification report for knn:'</span>)</span><br><span class="line">    print(classification_report(y_test, answer_knn))</span><br><span class="line">    print(<span class="string">'\n\nThe classification report for DT:'</span>)</span><br><span class="line">    print(classification_report(y_test, answer_dt))</span><br><span class="line">    print(<span class="string">'\n\nThe classification report for Bayes:'</span>)</span><br><span class="line">    print(classification_report(y_test, answer_gnb))</span><br></pre></td></tr></table></figure>
<pre><code>Start training knn
Training done
Prediction done
Start training DT
Training done
Prediction done
Start training Bayes
Training done
Prediction done


The classification report for knn:
             precision    recall  f1-score   support

        0.0       0.56      0.60      0.58    102341
        1.0       0.92      0.93      0.93     23699
        2.0       0.94      0.78      0.85     26864
        3.0       0.83      0.82      0.82     22132
        4.0       0.85      0.88      0.87     32033
        5.0       0.39      0.21      0.27     24646
        6.0       0.77      0.89      0.82     24577
        7.0       0.80      0.95      0.87     26271
       12.0       0.32      0.33      0.33     14281
       13.0       0.16      0.22      0.19     12727
       16.0       0.90      0.67      0.77     24445
       17.0       0.89      0.96      0.92     33034
       24.0       0.00      0.00      0.00      7733

avg / total       0.69      0.69      0.68    374783



The classification report for DT:
             precision    recall  f1-score   support

        0.0       0.53      0.80      0.64    102341
        1.0       0.79      0.96      0.87     23699
        2.0       0.84      0.86      0.85     26864
        3.0       0.93      0.73      0.82     22132
        4.0       0.62      0.87      0.73     32033
        5.0       0.69      0.51      0.59     24646
        6.0       0.05      0.01      0.02     24577
        7.0       0.33      0.15      0.20     26271
       12.0       0.59      0.64      0.61     14281
       13.0       0.65      0.47      0.55     12727
       16.0       0.57      0.07      0.13     24445
       17.0       0.86      0.85      0.86     33034
       24.0       0.40      0.31      0.35      7733

avg / total       0.60      0.63      0.59    374783



The classification report for Bayes:
             precision    recall  f1-score   support

        0.0       0.62      0.81      0.70    102341
        1.0       0.97      0.91      0.94     23699
        2.0       1.00      0.65      0.79     26864
        3.0       0.60      0.66      0.63     22132
        4.0       0.91      0.77      0.83     32033
        5.0       1.00      0.00      0.00     24646
        6.0       0.87      0.72      0.79     24577
        7.0       0.31      0.47      0.37     26271
       12.0       0.52      0.59      0.55     14281
       13.0       0.61      0.50      0.55     12727
       16.0       0.89      0.72      0.79     24445
       17.0       0.75      0.91      0.82     33034
       24.0       0.59      0.24      0.34      7733

avg / total       0.74      0.68      0.67    374783
</code></pre><h3 id="6-4-实验结论"><a href="#6-4-实验结论" class="headerlink" title="6.4 实验结论"></a>6.4 实验结论</h3><ul>
<li>从准确度的角度衡量，贝叶斯分类器的效果最好。</li>
<li>从召回率和F1值的角度衡量，k近邻效果最好。</li>
<li>贝叶斯分类器和k近邻的效果好于决策树。</li>
</ul>
<p>在所有的特征数据中，可能存在缺失值或者冗余特征。如果将这些特征不加处理地送入后续的计算，可能会导致模型准确度下降并且增大计算量。<br>在特征选择阶段，通常需要借助辅助软件(例如Weka)将数据进行可视化并进行统计。</p>
<h2 id="6-上证指数涨跌预测"><a href="#6-上证指数涨跌预测" class="headerlink" title="6 上证指数涨跌预测"></a>6 上证指数涨跌预测</h2><h3 id="6-1-数据介绍"><a href="#6-1-数据介绍" class="headerlink" title="6.1 数据介绍"></a>6.1 数据介绍</h3><p>网易财经上获得的上证指数的历史数据，爬取了20年的上证指数数据。</p>
<h3 id="6-2-实验目的"><a href="#6-2-实验目的" class="headerlink" title="6.2 实验目的"></a>6.2 实验目的</h3><p>根据给出当前时间前150天的历史数据，预测当天上证指数的涨跌。</p>
<h3 id="6-3-具体实现"><a href="#6-3-具体实现" class="headerlink" title="6.3 具体实现"></a>6.3 具体实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"> </span><br><span class="line"><span class="comment">#使用pandas库读取csv文件</span></span><br><span class="line">data=pd.read_csv(<span class="string">'datasets/stock/000777.csv'</span>,encoding=<span class="string">'gbk'</span>,parse_dates=[<span class="number">0</span>],index_col=<span class="number">0</span>)</span><br><span class="line"><span class="comment">#对数据进行排序，按0列排，升序，排序后覆盖原数据</span></span><br><span class="line">data.sort_index(<span class="number">0</span>,ascending=<span class="literal">True</span>,inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#选取150天数据</span></span><br><span class="line">dayfeature=<span class="number">150</span></span><br><span class="line"><span class="comment">#选取5列数据作为特征：收盘价、最高价、最低价、开盘价、成交量</span></span><br><span class="line">featurenum=<span class="number">5</span>*dayfeature</span><br><span class="line"><span class="comment">#记录150天的5个特征数</span></span><br><span class="line">x=np.zeros((data.shape[<span class="number">0</span>]-dayfeature,featurenum+<span class="number">1</span>))</span><br><span class="line"><span class="comment">#记录涨或者跌</span></span><br><span class="line">y=np.zeros((data.shape[<span class="number">0</span>]-dayfeature))</span><br><span class="line"></span><br><span class="line"><span class="comment">#将数据中的5个特征数存入X数组中</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,data.shape[<span class="number">0</span>]-dayfeature):</span><br><span class="line">    x[i,<span class="number">0</span>:featurenum]=np.array(data[i:i+dayfeature][[<span class="string">u'收盘价'</span>,<span class="string">u'最高价'</span>,<span class="string">u'最低价'</span>,<span class="string">u'开盘价'</span>,<span class="string">u'成交量'</span>]]).reshape((<span class="number">1</span>,featurenum))</span><br><span class="line">    x[i,featurenum]=data.ix[i+dayfeature][<span class="string">u'开盘价'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#如果当天收盘价高于开盘价，代表48涨，y[i]=1；反之y[i]=0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,data.shape[<span class="number">0</span>]-dayfeature):</span><br><span class="line">    <span class="keyword">if</span> data.ix[i+dayfeature][<span class="string">u'收盘价'</span>]&gt;=data.ix[i+dayfeature][<span class="string">u'开盘价'</span>]:</span><br><span class="line">        y[i]=<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        y[i]=<span class="number">0</span>          </span><br><span class="line"></span><br><span class="line"><span class="comment">#调用svm函数，并设置kernel参数，默认为rbf</span></span><br><span class="line">clf=svm.SVC(kernel=<span class="string">'rbf'</span>)</span><br><span class="line">result = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    <span class="comment">#X和Y的验证集和测试集，切分80%-20%的测试集</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = <span class="number">0.2</span>)</span><br><span class="line">    <span class="comment">#训练数据进行训练</span></span><br><span class="line">    clf.fit(x_train, y_train)</span><br><span class="line">    <span class="comment">#将预测数据和测试集的验证数据进行比对</span></span><br><span class="line">    result.append(np.mean(y_test == clf.predict(x_test)))</span><br><span class="line">print(<span class="string">"svm classifier accuacy:"</span>)</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>
<pre><code>d:\python\lib\site-packages\ipykernel_launcher.py:23: DeprecationWarning: 
.ix is deprecated. Please use
.loc for label based indexing or
.iloc for positional indexing

See the documentation here:
http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated


svm classifier accuacy:
[0.51465798045602607, 0.50488599348534202, 0.52442996742671011, 0.53311617806731815, 0.5450597176981542]
</code></pre><h2 id="7-线性回归"><a href="#7-线性回归" class="headerlink" title="7 线性回归"></a>7 线性回归</h2><h3 id="7-1-算法思想"><a href="#7-1-算法思想" class="headerlink" title="7.1 算法思想"></a>7.1 算法思想</h3><p>线性回归:使用形如$y=w^{T}X+b$的线性模型拟合数据输入和输出之间的映射关系的。</p>
<p>线性回归(Linear Regression)是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法。<br>线性回归利用称为线性回归方程的最小平方函数对一个或多个自变量和因变量之间关系进行建模。这种函数是一个或多个称为回归系数的模型参数的线性组合。只有一个自变量的情况称为简单回归，大于一个自变量情况的叫做多元回归。   </p>
<p>线性回归有很多实际的用途,分为以下两类:   </p>
<ol>
<li>如果目标是预测或者映射,线性回归可以用来对观测数据集的y和X的值拟合出一个预测模型。当完成这样一个模型以后，对于一个新增的X值，在没有给定与它相配对的y的情况下，可以用这个拟合过的模型预测出一个y值。</li>
<li>给定一个变量y和一些变量$x_{1}$,…，$x_{p}$，这些变量有可能与y相关，线性回归分析可以用来量化y与$x_{j}$之间相关性的强度，评估出与y不相关的$x_{j}$，并识别出哪些$x_{j}$的子集包含了关于y的冗余信息。</li>
</ol>
<h3 id="7-2-sklearn库实现步骤"><a href="#7-2-sklearn库实现步骤" class="headerlink" title="7.2 sklearn库实现步骤"></a>7.2 sklearn库实现步骤</h3><p>在sklearn库中，可以使用sklearn.linear_model.LinearRegression创建回归方程，主要参数有:</p>
<ul>
<li>fit-intercept:布尔型参数，表示是否计算该模型截距。可选参数。</li>
<li>normalize:布尔型参数，若为True，则X在回归前进行归一化。可选参数。默认值为False。</li>
<li>copy_X:布尔型参数，若为True，则X将被复制;否则将被覆盖。可选参数。默认值为True。</li>
<li>n_jobs:整型参数，表示用于计算的作业数量;若为一1，则用所有的CPU。可选参数。默认值为1。</li>
</ul>
<h3 id="7-3-算法应用"><a href="#7-3-算法应用" class="headerlink" title="7.3 算法应用"></a>7.3 算法应用</h3><p>应用背景：<br>与房价密切相关的除了单位的房价，还有房屋的尺寸。我们可以根据已知的房屋成交价和房屋的尺寸进行线性回归，继而可以对已知房屋尺寸，而未知房屋成交价格的实例进行成交价格的预测。   </p>
<p>实验目的：<br>对房屋成交信息建立回归方程，并依据回归方程对房屋价格进行预测。  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#建立datasets_X和datasets_Y用来存储数据中的房屋尺寸和房屋成交价格</span></span><br><span class="line">datasets_X = []</span><br><span class="line">datasets_Y = []</span><br><span class="line"><span class="comment">#打开数据集所在文件，读取数据</span></span><br><span class="line">fr = open(<span class="string">'datasets/prices.txt'</span>,<span class="string">'r'</span>)</span><br><span class="line"><span class="comment">#一次读取整个文件</span></span><br><span class="line">lines = fr.readlines()</span><br><span class="line"><span class="comment">#逐行进行操作，循环遍历所有数据</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">    <span class="comment">#去除数据文件中的逗号</span></span><br><span class="line">    items = line.strip().split(<span class="string">','</span>)</span><br><span class="line">    <span class="comment">#将读取的数据转换为int型，并分别写入datasets_X和datasets_Y</span></span><br><span class="line">    datasets_X.append(int(items[<span class="number">0</span>]))</span><br><span class="line">    datasets_Y.append(int(items[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment">#求得datasets_X的长度，即为数据的总数</span></span><br><span class="line">length = len(datasets_X)</span><br><span class="line"><span class="comment">#将datasets_X转换为数组，以符合线性回归拟合函数输入参数要求</span></span><br><span class="line">datasets_X = np.array(datasets_X).reshape([length,<span class="number">1</span>])</span><br><span class="line"><span class="comment">#将datasets_Y转换为数组</span></span><br><span class="line">datasets_Y = np.array(datasets_Y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#以数据datasets_X的最大值和最小值为范围，建立等差数列，方便后续画图</span></span><br><span class="line">minX = min(datasets_X)</span><br><span class="line">maxX = max(datasets_X)</span><br><span class="line">X = np.arange(minX,maxX).reshape([<span class="number">-1</span>,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#调用线性回归模块，建立回归方程，拟合数据</span></span><br><span class="line">linear = linear_model.LinearRegression()</span><br><span class="line">linear.fit(datasets_X, datasets_Y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图像中显示</span></span><br><span class="line">plt.scatter(datasets_X, datasets_Y, color = <span class="string">'red'</span>)</span><br><span class="line">plt.plot(X, linear.predict(X), color = <span class="string">'blue'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Area'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Price'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="http://polq2xceb.bkt.clouddn.com/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/output_16_0.png" alt="png"></p>
<h2 id="8-多项式回归"><a href="#8-多项式回归" class="headerlink" title="8 多项式回归"></a>8 多项式回归</h2><h3 id="8-1-算法思想"><a href="#8-1-算法思想" class="headerlink" title="8.1 算法思想"></a>8.1 算法思想</h3><p>多项式回归(Polynomial Regression)是研究一个因变量与一个或多个自变量间多项式的回归分析方法。如果自变量只有一个时，称为一元多项式回归;如果自变量有多个时，称为多元多项式回归。<br>一元m次多项式回归方程为: $$\hat{y}=b_{0}+b_{1}x+b_{2}x^{2}+\cdots +b_{m}x^{m}$$<br>二元二次多项式回归方程为:$$\hat{y}=b_{0}+b_{1}x_{1}+b_{2}x_{2}+b_{3}x_{1}^{2}+b_{4}x_{2}^{2}+ b_{5}x_{1}x_{2}$$</p>
<p>在一元回归分析中，如果依变量y与自变量X的关系为非线性的，但是又找不到适当的函数曲线来拟合，则可以采用一元多项式回归。<br>多项式回归的最大优点就是可以通过增加X的高次项对实测点进行逼近，直至满意为止。<br>事实上，多项式回归可以处理相当一类非线性问题，它在回归分析中占有重要的地位，因为任一函数都可以分段用多项式来逼近。 </p>
<h3 id="8-2-sklearn库实现步骤"><a href="#8-2-sklearn库实现步骤" class="headerlink" title="8.2 sklearn库实现步骤"></a>8.2 sklearn库实现步骤</h3><p>这里的多项式回归实际上是先将变量X处理成多项式特征，然后使用线性模型学习多项式特征的参数，以达到多项式回归的目的。<br>例如: X=$[X_{1}，X_{2}]$</p>
<ol>
<li>使用Polynomial「eatures构造X的二次多项式特征X_Poly:  $$X_Poly = [x_{1},x_{2},x_{1}x_{2},x_{1}^{2},x_{2}^{2}]$$</li>
<li>使用linear_model学习X_Poly和y之间的映射关系，即参数：$$w_{1}x_{1}+w_{2}x_{2}+w_{3}x_{1}x_{2}+w_{4}x_{1}^{2}+w_{5}x_{2}^{2} = y$$</li>
</ol>
<h3 id="8-3-算法应用"><a href="#8-3-算法应用" class="headerlink" title="8.3 算法应用"></a>8.3 算法应用</h3><p>应用背景：在上一节已经根据已知的房屋成交价和房屋的尺寸进行了线性回归，继而可以对已知房屋尺寸，而未知房屋成交价格的实例进行了成交价格的预测，但是在实际的应用中这样的拟合往往不够好，因此我们在此对该数据集进行多项式回归。  </p>
<p>实验目的：对房屋成交信息建立多项式回归方程，并依据回归方程对房屋价格进行预测。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"></span><br><span class="line"><span class="comment">#建立datasets_X和datasets_Y用来存储数据中的房屋尺寸和房屋成交价格</span></span><br><span class="line">datasets_X = []</span><br><span class="line">datasets_Y = []</span><br><span class="line"><span class="comment">#打开数据集所在文件，读取数据</span></span><br><span class="line">fr = open(<span class="string">'datasets/prices.txt'</span>,<span class="string">'r'</span>)</span><br><span class="line"><span class="comment">#一次读取整个文件</span></span><br><span class="line">lines = fr.readlines()</span><br><span class="line"><span class="comment">#逐行进行操作，循环遍历所有数据</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">    <span class="comment">#去除数据文件中的逗号</span></span><br><span class="line">    items = line.strip().split(<span class="string">','</span>)</span><br><span class="line">    <span class="comment">#将读取的数据转换为int型，并分别写入datasets_X和datasets_Y</span></span><br><span class="line">    datasets_X.append(int(items[<span class="number">0</span>]))</span><br><span class="line">    datasets_Y.append(int(items[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment">#求得datasets_X的长度，即为数据的总数</span></span><br><span class="line">length = len(datasets_X)</span><br><span class="line"><span class="comment">#将datasets_X转换为数组，以符合线性回归拟合函数输入参数要求</span></span><br><span class="line">datasets_X = np.array(datasets_X).reshape([length,<span class="number">1</span>])</span><br><span class="line"><span class="comment">#将datasets_Y转换为数组</span></span><br><span class="line">datasets_Y = np.array(datasets_Y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#以数据datasets_X的最大值和最小值为范围，建立等差数列，方便后续画图</span></span><br><span class="line">minX = min(datasets_X)</span><br><span class="line">maxX = max(datasets_X)</span><br><span class="line">X = np.arange(minX,maxX).reshape([<span class="number">-1</span>,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#degree=2表示建立datasets_X的二次多项式特征X_poly</span></span><br><span class="line">poly_reg = PolynomialFeatures(degree=<span class="number">2</span>)</span><br><span class="line">X_poly = poly_reg.fit_transform(datasets_X)</span><br><span class="line"><span class="comment">#创建线性回归，使用线性模型学习X_poly和datasets_Y之间的映射关系</span></span><br><span class="line">lin_reg_2 = linear_model.LinearRegression()</span><br><span class="line">lin_reg_2.fit(X_poly, datasets_Y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图像中显示</span></span><br><span class="line">plt.scatter(datasets_X, datasets_Y, color = <span class="string">'red'</span>)</span><br><span class="line">plt.plot(X, lin_reg_2.predict(poly_reg.fit_transform(X)), color = <span class="string">'blue'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Area'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Price'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="http://polq2xceb.bkt.clouddn.com/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/output_18_0.png" alt="png"></p>
<h2 id="9-岭回归"><a href="#9-岭回归" class="headerlink" title="9 岭回归"></a>9 岭回归</h2><h3 id="9-1-算法思想"><a href="#9-1-算法思想" class="headerlink" title="9.1 算法思想"></a>9.1 算法思想</h3><p>岭回归(ridge regression)是一种专用于共线性数据分析的有偏估计回归方法。是一种改良的最小二乘估计法，对某些数据的拟合要强于最小二乘法。</p>
<p>对于一般地线性回归问题，参数的求解采用的是最小二乘法，其目标函数如下：$argmin\left | Xw-y \right |^{2}$<br>参数w的求解，也可以使用如下矩阵方法进行：$w=(X^{T}X)^{-1}X^{T}y$<br>对于矩阵X，若某些列线性相关性较大(即训练样本中某些属性线性相关)，就会导致$X^{T}X$的值接近0，在计算$(X^{T}X)^{-1}$时就会出现不稳定性。传统的基于最小二乘法的线性回归缺乏稳定性。</p>
<p>岭回归的优化目标: $argmin\left | Xw-y \right |^{2}+\alpha \left | w \right |^{2}$<br>对应的矩阵求解方法为: $w=(X^{T}X + \alpha I)^{-1}X^{T}y$  </p>
<h3 id="9-2-sklearn库实现步骤"><a href="#9-2-sklearn库实现步骤" class="headerlink" title="9.2 sklearn库实现步骤"></a>9.2 sklearn库实现步骤</h3><p>在sklearn库中，可以使用sklearn.linear-model.Ridge调用岭回归模型，其主要参数有:</p>
<ul>
<li>alpha正则化因子，对应于损失函数中的$\alpha $。</li>
<li>fit-intercept:表示是否计算截距。</li>
<li>solver:设置计算参数的方法，可选参数‘auto’、’svd’、’sag‘等。  </li>
</ul>
<h3 id="9-3-算法应用"><a href="#9-3-算法应用" class="headerlink" title="9.3 算法应用"></a>9.3 算法应用</h3><p>数据介绍:<br>数据为某路口的交通流量监测数据，记录全年小时级别的车流量。</p>
<p>实验目的:<br>根据已有的数据创建多项式特征，使用岭回归模型代替一般的线性模型，对车流量的信息进行多项式回归。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用pandas库读取csv文件</span></span><br><span class="line">data = pd.read_csv(<span class="string">'datasets/traffic.csv'</span>,encoding=<span class="string">'gbk'</span>,parse_dates=[<span class="number">0</span>])</span><br><span class="line"><span class="comment">#X用于保存四个时间特征，Y用于保存车流量信息，作为标签</span></span><br><span class="line">X = np.zeros((data.shape[<span class="number">0</span>],<span class="number">4</span>),dtype=np.int16)</span><br><span class="line">Y = np.zeros((data.shape[<span class="number">0</span>],<span class="number">1</span>),dtype=np.int16)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,data.shape[<span class="number">0</span>]):</span><br><span class="line">    X[i] = np.array(data.iloc[i][<span class="number">1</span>:<span class="number">5</span>])</span><br><span class="line">    Y[i] = np.array(data.iloc[i][<span class="number">5</span>])</span><br><span class="line"><span class="comment">#用于创建最高次数为6次方的多项式特征，多次试验后决定采用6次</span></span><br><span class="line">poly = PolynomialFeatures(<span class="number">6</span>)</span><br><span class="line"><span class="comment"># 创建多项式特征</span></span><br><span class="line">X = poly.fit_transform(X)</span><br><span class="line"><span class="comment">#将所有数据分为训练集和测试集</span></span><br><span class="line">train_set_X, test_set_X, train_set_Y, test_set_Y =train_test_split(X,Y,test_size=<span class="number">0.3</span>,random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建岭回归示例</span></span><br><span class="line">clf = Ridge(alpha=<span class="number">1.0</span>, fit_intercept = <span class="literal">True</span>)</span><br><span class="line">clf.fit(train_set_X,train_set_Y)</span><br><span class="line">clf.score(test_set_X,test_set_Y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#绘制一段200到300范围内的拟合曲线</span></span><br><span class="line">start = <span class="number">200</span></span><br><span class="line">end = <span class="number">300</span></span><br><span class="line">Y_pre = clf.predict(X)</span><br><span class="line">time = np.arange(start,end)</span><br><span class="line">plt.plot(time,Y[start:end],<span class="string">'b'</span>,label=<span class="string">'real'</span>)</span><br><span class="line">plt.plot(time,Y_pre[start:end],<span class="string">'r'</span>,label=<span class="string">'predict'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'upper left'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>d:\python\lib\site-packages\scipy\linalg\basic.py:223: RuntimeWarning: scipy.linalg.solve
Ill-conditioned matrix detected. Result is not guaranteed to be accurate.
Reciprocal condition number: 5.032398761251724e-21
  &apos; condition number: {}&apos;.format(rcond), RuntimeWarning)
</code></pre><p><img src="http://polq2xceb.bkt.clouddn.com/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/output_20_1.png" alt="png"></p>
<h2 id="10-手写数字识别"><a href="#10-手写数字识别" class="headerlink" title="10 手写数字识别"></a>10 手写数字识别</h2><h3 id="10-1-背景介绍"><a href="#10-1-背景介绍" class="headerlink" title="10.1 背景介绍"></a>10.1 背景介绍</h3><p>手写识别是常见的图像识别任务。计算机通过手写体图片来识别出图片中的字，与印刷字体不同的是，不同人的手写体风格迥异，大小不一，造成了计算机对手写识别任务的一些困难。<br>数字手写体识别由于其有限的类别(O-9共10个数字)成为了相对简单的手写识别任务。DBRHD和MNIST是常用的两个数字手写识别数据集。已有许多模型在MNIST或DBRHD数据集上进行了实验，有些模型对数据集进行了偏斜矫正，甚至在数据集上进行了人为的扭曲、偏移、缩放及失真等操作以获取更加多样性的样本，使得模型更具有泛化性。</p>
<h4 id="10-1-1-MNIST数据集"><a href="#10-1-1-MNIST数据集" class="headerlink" title="10.1.1 MNIST数据集"></a>10.1.1 MNIST数据集</h4><p>MNIST是一个包含数字0一9的手写体图片数据集，图片已归一化为以手写数字为中心的28*28规格的图片。MNIS丁由训练集与测试集两个部分组成，各部分规模如下:</p>
<ul>
<li>训练集:60,000个手写体图片及对应标签</li>
<li>测试集:10,000个手写体图片及对应标签</li>
</ul>
<h4 id="10-1-2-MNIST数据集"><a href="#10-1-2-MNIST数据集" class="headerlink" title="10.1.2 MNIST数据集"></a>10.1.2 MNIST数据集</h4><p>DBRHD(Pen-Based Recognition of Handwritten Digits Data Set)是UCI的机器学习中心提供的数字手写体数据库。DBRHD数据集包含大量的数字0-9的手写体图片，这些图片来源于44位不同的人的手写数字，图片已归一化为以手写数字为中心的32*32规格的图片。DBRHD的训练集与测试集组成如下:</p>
<ul>
<li>训练集:7,494个手写体图片及对应标签，来源于40位手写者</li>
<li>测试集:3,498个手写体图片及对应标签，来源于14位手写者 </li>
</ul>
<p>DBRHD数据集特点:</p>
<ul>
<li>去掉了图片颜色等复杂因素，将手写体数字图片转化为训练数据为大小32*32的文本阵</li>
<li>空白区域使用0表示，字迹区域使用1表示。</li>
</ul>
<h3 id="10-2-神经网络实现"><a href="#10-2-神经网络实现" class="headerlink" title="10.2 神经网络实现"></a>10.2 神经网络实现</h3><p>利用sklearn来训练一个简单的全连接神经网络，即多层感知机（Multilayer perceptron，MLP）用于识别数据集DBRHD的手写数字。</p>
<h4 id="10-2-1-算法思想"><a href="#10-2-1-算法思想" class="headerlink" title="10.2.1 算法思想"></a>10.2.1 算法思想</h4><p>MLP（Multi-layer Perceptron），即多层感知器，是一种前向结构的人工神经网络，映射一组输入向量到一组输出向量。MLP可以被看做是一个有向图，由多个节点层组成，每一层全连接到下一层。除了输入节点，每个节点都是一个带有非线性激活函数的神经元（或称处理单元）。一种被称为反向传播算法的监督学习方法常被用来训练MLP。MLP是感知器的推广，克服了感知器不能对线性不可分数据进行识别的弱点。<br>MLP的输入与输出层，中间隐藏层的层数和神经元的个数设置都将影响该MLP模型的准确率。</p>
<h4 id="10-2-2-算法实现"><a href="#10-2-2-算法实现" class="headerlink" title="10.2.2 算法实现"></a>10.2.2 算法实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np     <span class="comment">#导入numpy工具包</span></span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> listdir <span class="comment">#使用listdir模块，用于访问本地文件</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier </span><br><span class="line"> </span><br><span class="line"><span class="comment">#将加载的32*32的图片矩阵展开成一列向量</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">img2vector</span><span class="params">(fileName)</span>:</span>    </span><br><span class="line">    retMat = np.zeros([<span class="number">1024</span>],int) <span class="comment">#定义返回的矩阵，大小为1*1024</span></span><br><span class="line">    fr = open(fileName)           <span class="comment">#打开包含32*32大小的数字文件 </span></span><br><span class="line">    lines = fr.readlines()        <span class="comment">#读取文件的所有行</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">32</span>):           <span class="comment">#遍历文件所有行</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">32</span>):       <span class="comment">#并将数字存放在retMat中     </span></span><br><span class="line">            retMat[i*<span class="number">32</span>+j] = lines[i][j]    </span><br><span class="line">    <span class="keyword">return</span> retMat</span><br><span class="line"> </span><br><span class="line"><span class="comment">#将样本标签转换为one-hot向量</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readDataSet</span><span class="params">(path)</span>:</span>    </span><br><span class="line">    fileList = listdir(path)    <span class="comment">#获取文件夹下的所有文件 </span></span><br><span class="line">    numFiles = len(fileList)    <span class="comment">#统计需要读取的文件的数目</span></span><br><span class="line">    dataSet = np.zeros([numFiles,<span class="number">1024</span>],int) <span class="comment">#用于存放所有的数字文件</span></span><br><span class="line">    hwLabels = np.zeros([numFiles,<span class="number">10</span>])      <span class="comment">#用于存放对应的one-hot标签</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numFiles):   <span class="comment">#遍历所有的文件</span></span><br><span class="line">        filePath = fileList[i]  <span class="comment">#获取文件名称/路径      </span></span><br><span class="line">        digit = int(filePath.split(<span class="string">'_'</span>)[<span class="number">0</span>])  <span class="comment">#通过文件名获取标签      </span></span><br><span class="line">        hwLabels[i][digit] = <span class="number">1.0</span>        <span class="comment">#将对应的one-hot标签置1</span></span><br><span class="line">        dataSet[i] = img2vector(path +<span class="string">'/'</span>+filePath) <span class="comment">#读取文件内容   </span></span><br><span class="line">    <span class="keyword">return</span> dataSet,hwLabels</span><br><span class="line"> </span><br><span class="line"><span class="comment">#加载数据，将训练的图片存放在train_dataset中，对应的标签则存在train_hwLables中</span></span><br><span class="line">train_dataSet, train_hwLabels = readDataSet(<span class="string">'datasets/trainingDigits'</span>)</span><br><span class="line"><span class="comment">#构建神经网络：设置网络的隐藏层数为1，各隐藏层神经元个数为100，激活函数使用logistic，优化方法为adam法，初始学习率为0.0001，最大迭代次数为2000</span></span><br><span class="line">clf = MLPClassifier(hidden_layer_sizes=(<span class="number">100</span>,),activation=<span class="string">'logistic'</span>, solver=<span class="string">'adam'</span>,learning_rate_init = <span class="number">0.0001</span>, max_iter=<span class="number">2000</span>)</span><br><span class="line"><span class="comment">#使用训练数据训练构建好的神经网络</span></span><br><span class="line">clf.fit(train_dataSet,train_hwLabels)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#加载数据集</span></span><br><span class="line">dataSet,hwLabels = readDataSet(<span class="string">'datasets/testDigits'</span>)</span><br><span class="line"><span class="comment">#使用训练好的MLP对训练集进行预测，并计算错误率</span></span><br><span class="line">res = clf.predict(dataSet)   <span class="comment">#对测试集进行预测</span></span><br><span class="line">error_num = <span class="number">0</span>                <span class="comment">#统计预测错误的数目</span></span><br><span class="line">num = len(dataSet)           <span class="comment">#测试集的数目</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(num):         <span class="comment">#遍历预测结果</span></span><br><span class="line">    <span class="comment">#比较长度为10的数组，返回包含01的数组，0为不同，1为相同</span></span><br><span class="line">    <span class="comment">#若预测结果与真实结果相同，则10个数字全为1，否则不全为1</span></span><br><span class="line">    <span class="keyword">if</span> np.sum(res[i] == hwLabels[i]) &lt; <span class="number">10</span>: </span><br><span class="line">        error_num += <span class="number">1</span>                     </span><br><span class="line">print(<span class="string">"Total num:"</span>,num,<span class="string">" Wrong num:"</span>, error_num,<span class="string">"  WrongRate:"</span>,error_num / float(num))</span><br></pre></td></tr></table></figure>
<pre><code>Total num: 946  Wrong num: 36   WrongRate: 0.03805496828752643
</code></pre><h3 id="10-3-KNN分类器实现"><a href="#10-3-KNN分类器实现" class="headerlink" title="10.3 KNN分类器实现"></a>10.3 KNN分类器实现</h3><p>利用sklearn来训练一个K最近邻（k-Nearest Neighbor，KNN分类器，用于识别数据集DBRHD的手写数字。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np     <span class="comment">#导入numpy工具包</span></span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> listdir <span class="comment">#使用listdir模块，用于访问本地文件</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> neighbors</span><br><span class="line"> </span><br><span class="line"><span class="comment">#将加载的32*32的图片矩阵展开成一列向量</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">img2vector</span><span class="params">(fileName)</span>:</span>    </span><br><span class="line">    retMat = np.zeros([<span class="number">1024</span>],int) <span class="comment">#定义返回的矩阵，大小为1*1024</span></span><br><span class="line">    fr = open(fileName)           <span class="comment">#打开包含32*32大小的数字文件 </span></span><br><span class="line">    lines = fr.readlines()        <span class="comment">#读取文件的所有行</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">32</span>):           <span class="comment">#遍历文件所有行</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">32</span>):       <span class="comment">#并将数字存放在retMat中     </span></span><br><span class="line">            retMat[i*<span class="number">32</span>+j] = lines[i][j]    </span><br><span class="line">    <span class="keyword">return</span> retMat</span><br><span class="line"> </span><br><span class="line"><span class="comment">#加载训练数据，而非one-hot向量</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readDataSet</span><span class="params">(path)</span>:</span>    </span><br><span class="line">    fileList = listdir(path)    <span class="comment">#获取文件夹下的所有文件 </span></span><br><span class="line">    numFiles = len(fileList)    <span class="comment">#统计需要读取的文件的数目</span></span><br><span class="line">    dataSet = np.zeros([numFiles,<span class="number">1024</span>],int)    <span class="comment">#用于存放所有的数字文件</span></span><br><span class="line">    hwLabels = np.zeros([numFiles])<span class="comment">#用于存放对应的标签(与神经网络的不同)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numFiles):      <span class="comment">#遍历所有的文件</span></span><br><span class="line">        filePath = fileList[i]     <span class="comment">#获取文件名称/路径   </span></span><br><span class="line">        digit = int(filePath.split(<span class="string">'_'</span>)[<span class="number">0</span>])   <span class="comment">#通过文件名获取标签     </span></span><br><span class="line">        hwLabels[i] = digit        <span class="comment">#直接存放数字，并非one-hot向量</span></span><br><span class="line">        dataSet[i] = img2vector(path +<span class="string">'/'</span>+filePath)    <span class="comment">#读取文件内容 </span></span><br><span class="line">    <span class="keyword">return</span> dataSet,hwLabels</span><br><span class="line"> </span><br><span class="line"><span class="comment">#加载数据，将训练的图片存放在train_dataset中，对应的标签则存在train_hwLables中</span></span><br><span class="line">train_dataSet, train_hwLabels = readDataSet(<span class="string">'datasets/trainingDigits'</span>)</span><br><span class="line"><span class="comment">#构建KNN分类器：设置查找算法以及邻居点数量(k)值</span></span><br><span class="line">knn = neighbors.KNeighborsClassifier(algorithm=<span class="string">'kd_tree'</span>, n_neighbors=<span class="number">3</span>)</span><br><span class="line">knn.fit(train_dataSet, train_hwLabels)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#加载测试集</span></span><br><span class="line">dataSet,hwLabels = readDataSet(<span class="string">'datasets/testDigits'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用训练好的KNN对训练集进行预测，并计算错误率</span></span><br><span class="line">res = knn.predict(dataSet)  <span class="comment">#对测试集进行预测</span></span><br><span class="line">error_num = np.sum(res != hwLabels) <span class="comment">#统计分类错误的数目KNNz</span></span><br><span class="line">num = len(dataSet)          <span class="comment">#测试集的数目</span></span><br><span class="line">print(<span class="string">"Total num:"</span>,num,<span class="string">" Wrong num:"</span>, error_num,<span class="string">"  WrongRate:"</span>,error_num / float(num))</span><br></pre></td></tr></table></figure>
<pre><code>Total num: 946  Wrong num: 12   WrongRate: 0.0126849894292
</code></pre>
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
            <a href="/tags/python/" rel="tag"># python</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/post/42646.html" rel="next" title="无监督学习">
                <i class="fa fa-chevron-left"></i> 无监督学习
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/post/16442f6b.html" rel="prev" title="CORDIC算法介绍及其HLS实现">
                CORDIC算法介绍及其HLS实现 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Inhaltsverzeichnis
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Übersicht
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">WaveZhu</p>
              <div class="site-description motion-element" itemprop="description"></div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">3</span>
                    <span class="site-state-item-name">Artikel</span>
                  </a>
                </div>
              

              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">4</span>
                    <span class="site-state-item-name">schlagwörter</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-概述"><span class="nav-number">1.</span> <span class="nav-text">1 概述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-分类学习"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 分类学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-分类学习评价"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 分类学习评价</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-回归学习"><span class="nav-number">1.3.</span> <span class="nav-text">1.3 回归学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-交叉验证"><span class="nav-number">1.4.</span> <span class="nav-text">1.4 交叉验证</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-K临近分类器"><span class="nav-number">2.</span> <span class="nav-text">2 K临近分类器</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-算法思想"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 算法思想</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-sklearn库实现步骤"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 sklearn库实现步骤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-算法应用"><span class="nav-number">2.3.</span> <span class="nav-text">2.3 算法应用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-决策树分类器"><span class="nav-number">3.</span> <span class="nav-text">3 决策树分类器</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-算法思想"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 算法思想</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-sklearn库实现步骤"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 sklearn库实现步骤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-算法应用"><span class="nav-number">3.3.</span> <span class="nav-text">3.3 算法应用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-朴素贝叶斯分类器"><span class="nav-number">4.</span> <span class="nav-text">4 朴素贝叶斯分类器</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-算法思想"><span class="nav-number">4.1.</span> <span class="nav-text">4.1 算法思想</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-sklearn库实现步骤"><span class="nav-number">4.2.</span> <span class="nav-text">4.2 sklearn库实现步骤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-算法应用"><span class="nav-number">4.3.</span> <span class="nav-text">4.3 算法应用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-人体运动状态预测"><span class="nav-number">5.</span> <span class="nav-text">5 人体运动状态预测</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-数据介绍"><span class="nav-number">5.1.</span> <span class="nav-text">5.1 数据介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-实验目的"><span class="nav-number">5.2.</span> <span class="nav-text">5.2 实验目的</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-具体实现"><span class="nav-number">5.3.</span> <span class="nav-text">5.3 具体实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-实验结论"><span class="nav-number">5.4.</span> <span class="nav-text">6.4 实验结论</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-上证指数涨跌预测"><span class="nav-number">6.</span> <span class="nav-text">6 上证指数涨跌预测</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#6-1-数据介绍"><span class="nav-number">6.1.</span> <span class="nav-text">6.1 数据介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-2-实验目的"><span class="nav-number">6.2.</span> <span class="nav-text">6.2 实验目的</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-3-具体实现"><span class="nav-number">6.3.</span> <span class="nav-text">6.3 具体实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-线性回归"><span class="nav-number">7.</span> <span class="nav-text">7 线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#7-1-算法思想"><span class="nav-number">7.1.</span> <span class="nav-text">7.1 算法思想</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-2-sklearn库实现步骤"><span class="nav-number">7.2.</span> <span class="nav-text">7.2 sklearn库实现步骤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-3-算法应用"><span class="nav-number">7.3.</span> <span class="nav-text">7.3 算法应用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-多项式回归"><span class="nav-number">8.</span> <span class="nav-text">8 多项式回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1-算法思想"><span class="nav-number">8.1.</span> <span class="nav-text">8.1 算法思想</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-2-sklearn库实现步骤"><span class="nav-number">8.2.</span> <span class="nav-text">8.2 sklearn库实现步骤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-3-算法应用"><span class="nav-number">8.3.</span> <span class="nav-text">8.3 算法应用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-岭回归"><span class="nav-number">9.</span> <span class="nav-text">9 岭回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#9-1-算法思想"><span class="nav-number">9.1.</span> <span class="nav-text">9.1 算法思想</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-2-sklearn库实现步骤"><span class="nav-number">9.2.</span> <span class="nav-text">9.2 sklearn库实现步骤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-3-算法应用"><span class="nav-number">9.3.</span> <span class="nav-text">9.3 算法应用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-手写数字识别"><span class="nav-number">10.</span> <span class="nav-text">10 手写数字识别</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#10-1-背景介绍"><span class="nav-number">10.1.</span> <span class="nav-text">10.1 背景介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#10-1-1-MNIST数据集"><span class="nav-number">10.1.1.</span> <span class="nav-text">10.1.1 MNIST数据集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-1-2-MNIST数据集"><span class="nav-number">10.1.2.</span> <span class="nav-text">10.1.2 MNIST数据集</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-2-神经网络实现"><span class="nav-number">10.2.</span> <span class="nav-text">10.2 神经网络实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#10-2-1-算法思想"><span class="nav-number">10.2.1.</span> <span class="nav-text">10.2.1 算法思想</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-2-2-算法实现"><span class="nav-number">10.2.2.</span> <span class="nav-text">10.2.2 算法实现</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-3-KNN分类器实现"><span class="nav-number">10.3.</span> <span class="nav-text">10.3 KNN分类器实现</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WaveZhu</span>

  

  
</div>


  <div class="powered-by">Erstellt mit  <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Design – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.0.1</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=7.0.1"></script>

  <script src="/js/src/motion.js?v=7.0.1"></script>



  
  


  <script src="/js/src/schemes/muse.js?v=7.0.1"></script>



  
  <script src="/js/src/scrollspy.js?v=7.0.1"></script>
<script src="/js/src/post-details.js?v=7.0.1"></script>



  


  <script src="/js/src/next-boot.js?v=7.0.1"></script>


  

  

  

  


  


  




  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  

  

  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


  

  

  

  

  

  

  

  

</body>
</html>
